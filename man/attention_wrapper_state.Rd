% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/seq2seq.R
\name{attention_wrapper_state}
\alias{attention_wrapper_state}
\title{Attention Wrapper State}
\usage{
attention_wrapper_state(
  object,
  cell_state,
  attention,
  alignments,
  alignment_history,
  attention_state
)
}
\arguments{
\item{object}{Model or layer object}

\item{cell_state}{The state of the wrapped RNNCell at the previous time step.}

\item{attention}{The attention emitted at the previous time step.}

\item{alignments}{A single or tuple of Tensor(s) containing the alignments
emitted at the previous time step for each attention mechanism.}

\item{alignment_history}{(if enabled) a single or tuple of TensorArray(s)
containing alignment matrices from all time steps for each attention mechanism.
Call stack() on each to convert to a Tensor.}

\item{attention_state}{A single or tuple of nested objects containing attention
mechanism state for each attention mechanism. The objects may contain Tensors or
TensorArrays.}
}
\value{
None
}
\description{
`namedlist` storing the state of a `attention_wrapper`.
}
